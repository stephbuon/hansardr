#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs.extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract.adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
posextract <- import("posextract")
py_list_attributes(posextract)
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
os <- import("os")
os <- import("pandas")
os <- import("posextract")
os <- import("pandas")
py_install("pandas")
py_install("posextract'")
py_install("posextract")
posextract <- import("posextract")
py_install("bloop")
py_install("bloophjghghj")
py_install("posextract")
library("reticulate")
#' @export
posextract_install <- function() {
if(dir.exists(paste0(virtualenv_root(), '/r-posextract'))) {
print("posextract has already been installed. Reinstall?")
print("Press 1 for reinstall")
print("Press 2 to pass")
input <- readline(prompt="Select Option: ")
if(input == 1) {
virtualenv_create("r-posextract", install_python(), packages = c("pandas", "spacy", "posextract"))
#system(command = "python -m spacy download en_core_web_sm")
}
else if(input == 2) {
print("Skipping Install") }
else {
print("Not a valid option. Exiting.") } }
else {
virtualenv_create("r-posextract", install_python(), packages = c("pandas", "spacy"))
system(command = "python -m spacy download en_core_web_sm") } }
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
#posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
#' @export
posextract_install <- function() {
if(dir.exists(paste0(virtualenv_root(), '/r-posextract'))) {
print("posextract has already been installed. Reinstall?")
print("Press 1 for reinstall")
print("Press 2 to pass")
input <- readline(prompt="Select Option: ")
if(input == 1) {
virtualenv_create("r-posextract", install_python(), packages = c("pandas", "spacy", "posextract"))
#system(command = "python -m spacy download en_core_web_sm")
}
else if(input == 2) {
print("Skipping Install") }
else {
print("Not a valid option. Exiting.") } }
else {
virtualenv_create("r-posextract", install_python(), packages = c("pandas", "spacy"))
system(command = "python -m spacy download en_core_web_sm") } }
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
#posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
#' @export
posextract_initialize <- function() {
use_virtualenv("r-posextract") }
library("reticulate")
posextract_install()
posextract_initialize()
extract_adj_noun_pairs()
#' @export
extract_adj_noun_pairs <- function(hansard, col) {
#posextract <- reticulate::import_from_path("posextract.extract_adj_noun_pairs", "~/projects/posextractr/") # I won't need this once posextract has been submitted to pypi
posextract <- import("posextract")
# parse here in R, then pass parsed object to extract_adj_noun_pairs()
hansard <- posextract$adj_noun_pairs$extract(hansard, col) # change to (hansard, ...) maybe
hansard[] <- lapply(hansard, as.vector)
return(hansard) }
extract_adj_noun_pairs()
hansard <- read_csv("/home/stephbuon/data/samples/full_hansard_sample.csv")
library(tidyverse)
hansard <- read_csv("/home/stephbuon/data/samples/full_hansard_sample.csv")
extract_adj_noun_pairs(hansard, 'text')
system(command = "python -m spacy download en_core_web_sm")
a <- extract_adj_noun_pairs(hansard, 'text')
View(a)
require(devtools)
install_github("stephbuon/posextractr")
library(posextractr)
library(tidyverse)
hansard <- read_csv("/home/stephbuon/data/samples/full_hansard_sample.csv")
extract_adj_noun_pairs()
library('reticulate')
extract_adj_noun_pairs(hansard, 'text')
a <- extract_adj_noun_pairs(hansard, 'text')
library(hansardr)
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
a <- extract_adj_noun_pairs(hansard_sample, 'text')
View(a)
library("hansardr")
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
adj_noun_pairs_in_hansard <- extract_adj_noun_pairs(hansard_sample, "text")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair)
ggplot(data = adj_noun_pairs_in_hansard,
aes(x = n, y = adj_noun_pair)) +
geom_bar(stat = "identity", width = 0.5) +
coord_flip()
aes(x = n, y = adj_noun_pair) +
)
ggplot(data = adj_noun_pairs_count,
aes(x = n, y = adj_noun_pair)) +
geom_bar(stat = "identity", width = 0.5) +
coord_flip()
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Top Lemmatized Adjective-Noun Pairs with Woman",
#subtitle = "From 19th-century British Parliamentary Debate Text",
caption = "Searching the Hansard Parliamentary Debates from 1870-79",
x = "Triple",
y = "count")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(10)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Top Lemmatized Adjective-Noun Pairs with Woman",
#subtitle = "From 19th-century British Parliamentary Debate Text",
caption = "Searching the Hansard Parliamentary Debates from 1870-79",
x = "Triple",
y = "count")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n))
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(10)
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:10)
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(:10)
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:10)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Top Lemmatized Adjective-Noun Pairs with Woman",
#subtitle = "From 19th-century British Parliamentary Debate Text",
caption = "Searching the Hansard Parliamentary Debates from 1870-79",
x = "Triple",
y = "count")
library("hansardr")
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
adj_noun_pairs_in_hansard <- extract_adj_noun_pairs(hansard_sample, "text")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:10)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Examples of Adjective-Noun Pairs",
caption = "Searching the 1800s Hansard Parliamentary Debates",
x = "Adjective-Noun Pair",
y = "Count")
library("hansardr")
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
adj_noun_pairs_in_hansard <- extract_adj_noun_pairs(hansard_sample, "text")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:10)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Examples of Adjective-Noun Pairs",
caption = "Searching the Hansard Parliamentary Debates",
x = "Adjective-Noun Pair",
y = "Count")
library("hansardr")
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
adj_noun_pairs_in_hansard <- extract_adj_noun_pairs(hansard_sample, "text")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:10)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Examples of Adjective-Noun Pairs",
caption = "Searching the Hansard Parliamentary Debates",
x = "Adjective-Noun Pair",
y = "Count")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:20)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Examples of Adjective-Noun Pairs",
caption = "Searching the Hansard Parliamentary Debates",
x = "Adjective-Noun Pair",
y = "Count")
library("hansardr")
data("hansard_1800")
hansard_sample <- hansard_1800 %>%
sample_n(100)
adj_noun_pairs_in_hansard <- extract_adj_noun_pairs(hansard_sample, "text")
adj_noun_pairs_count <- adj_noun_pairs_in_hansard %>%
count(adj_noun_pair) %>%
arrange(desc(n)) %>%
slice(1:20)
ggplot(data = adj_noun_pairs_count) +
geom_col(aes(x = reorder(adj_noun_pair, n),
y = n),
fill = "steel blue") +
coord_flip() +
labs(title = "Examples of Adjective-Noun Pairs",
caption = "Searching the Hansard Parliamentary Debates",
x = "Adjective-Noun Pair",
y = "Count")
shiny::runApp('congress-shiny')
runApp('congress-shiny')
runApp('congress-shiny')
shiny::runApp('congress-shiny')
data_dir <- "~/projects/congress-shiny/app/app-data/small_congress/"
runApp('congress-shiny')
shiny::runApp('congress-shiny')
data_dir <- "~/projects/congress-shiny/app/app-data/small_congress/"
runApp('congress-shiny')
runApp('congress-shiny')
shiny::runApp('congress-shiny')
data_dir <- "~/projects/congress-shiny/app/app-data/small_congress/"
runApp('congress-shiny')
runApp('congress-shiny')
runApp('congress-shiny')
library(tidyverse)
code_dir <- "~/projects/congress-shiny/preprocess-code/collocates/collocates-functions/"
source(paste0(code_dir, "clean_collocates.R"))
source(paste0(code_dir, "count_collocates.R"))
source(paste0(code_dir, "score_collocates.R"))
keyword <- "all"
#keyword <- "concerns"
#keyword <- "property"
data_dir <- "~/home/stephbuon/projects/congress-shiny/app/app-data/collocates/"
collocates <- read_csv(paste0(data_dir, keyword, "_adj_noun_collocates.csv"))
library(tidyverse)
code_dir <- "~/projects/congress-shiny/preprocess-code/collocates/collocates-functions/"
source(paste0(code_dir, "clean_collocates.R"))
source(paste0(code_dir, "count_collocates.R"))
source(paste0(code_dir, "score_collocates.R"))
keyword <- "all"
#keyword <- "concerns"
#keyword <- "property"
data_dir <- "~/projects/congress-shiny/app/app-data/collocates/"
collocates <- read_csv(paste0(data_dir, keyword, "_adj_noun_collocates.csv"))
collocates <- clean_collocates(collocates, keyword)
collocates <- count_collocates(collocates)
if (keyword == "speakers") {
collocates <- searchable_speaker(collocates) }
collocates <- score_collocates(collocates, keyword)
write_csv(collocates, paste0(dir, "clean_", keyword, "_adj_noun_collocates.csv"))
write_csv(collocates, paste0(data_dir, "clean_", keyword, "_adj_noun_collocates.csv"))
shiny::runApp('congress-shiny')
data_dir <- "~/projects/congress-shiny/app/app-data/"
runApp('congress-shiny')
runApp('congress-shiny/app/modules/context/context.R')
runApp('congress-shiny/app/modules/context/context.R')
runApp('congress-shiny')
shiny::runApp('congress-shiny')
data_dir <- "~/projects/congress-shiny/app/app-data/"
runApp('congress-shiny')
shiny::runApp('hansard-shiny/app')
load("~/projects/hansardr/data/debate_metadata_1800.RData")
load("~/projects/hansardr/data/file_metadata_1800.RData")
load("~/projects/hansardr/data/events.RData")
load("~/projects/hansardr/data/hansard_1800.RData")
View(file_metadata_1800)
View(hansard_1800)
library(tidyverse)
library(data.table)
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv")
hansard_speakers <- fread("/home/stephbuon/data/hansard_results.csv")
View(hansard_speakers)
setwd("~/projects/hansardr")
library(tidyverse)
library(data.table)
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv") %>%
mutate(year = year(hansard$speechdate)) %>%
mutate(decade = year - year %% 10)
hansard_speakers <- fread("/home/stephbuon/data/hansard_results.csv")
speaker_metadata_1800 <- hansard %>%
filter(decade == 1800)
save(speaker_metadata_1800, file="data/speaker_metadata_1800.RData")
speaker_metadata_1810 <- hansard  %>%
filter(decade == 1810)
save(speaker_metadata_1810, file="data/speaker_metadata_1810.RData")
speaker_metadata_1820 <- hansard  %>%
filter(decade == 1820)
save(speaker_metadata_1820, file="data/speaker_metadata_1820.RData")
speaker_metadata_1830 <- hansard  %>%
filter(decade == 1830)
save(speaker_metadata_1830, file="data/speaker_metadata_1830.RData")
speaker_metadata_1840 <- hansard  %>%
filter(decade == 1840)
save(speaker_metadata_1840, file="data/speaker_metadata_1840.RData")
speaker_metadata_1850 <- hansard  %>%
filter(decade == 1850)
save(speaker_metadata_1850, file="data/speaker_metadata_1850.RData")
speaker_metadata_1860 <- hansard  %>%
filter(decade == 1860)
save(debate_metadata_1860, file="data/debate_metadata_1860.RData")
library(tidyverse)
library(data.table)
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv") %>%
mutate(year = year(hansard$speechdate)) %>%
mutate(decade = year - year %% 10)
hansard_speakers <- fread("/home/stephbuon/data/hansard_results.csv")
speaker_metadata_1800 <- hansard %>%
filter(decade == 1800)
save(speaker_metadata_1800, file="data/speaker_metadata_1800.RData")
speaker_metadata_1810 <- hansard  %>%
filter(decade == 1810)
save(speaker_metadata_1810, file="data/speaker_metadata_1810.RData")
speaker_metadata_1820 <- hansard  %>%
filter(decade == 1820)
save(speaker_metadata_1820, file="data/speaker_metadata_1820.RData")
speaker_metadata_1830 <- hansard  %>%
filter(decade == 1830)
save(speaker_metadata_1830, file="data/speaker_metadata_1830.RData")
speaker_metadata_1840 <- hansard  %>%
filter(decade == 1840)
save(speaker_metadata_1840, file="data/speaker_metadata_1840.RData")
speaker_metadata_1850 <- hansard  %>%
filter(decade == 1850)
save(speaker_metadata_1850, file="data/speaker_metadata_1850.RData")
speaker_metadata_1860 <- hansard  %>%
filter(decade == 1860)
save(speaker_metadata_1860, file="data/speaker_metadata_1860.RData")
speaker_metadata_1870 <- hansard  %>%
filter(decade == 1870)
save(speaker_metadata_1870, file="data/speaker_metadata_1870.RData")
speaker_metadata_1880 <- hansard  %>%
filter(decade == 1880)
save(speaker_metadata_1880, file="data/speaker_metadata_1880.RData")
speaker_metadata_1890 <- hansard  %>%
filter(decade == 1890)
save(speaker_metadata_1890, file="data/speaker_metadata_1890.RData")
speaker_metadata_1900 <- hansard  %>%
filter(decade == 1900)
save(speaker_metadata_1900, file="data/speaker_metadata_1900.RData")
debate_metadata_1800 <- hansard %>%
filter(decade == 1800) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1800, file="data/debate_metadata_1800.RData")
debate_metadata_1810 <- hansard %>%
filter(decade == 1810) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1810, file="data/debate_metadata_1810.RData")
debate_metadata_1820 <- hansard %>%
filter(decade == 1820) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1820, file="data/debate_metadata_1820.RData")
debate_metadata_1830 <- hansard %>%
filter(decade == 1830) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1830, file="data/debate_metadata_1830.RData")
debate_metadata_1840 <- hansard %>%
filter(decade == 1840) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1840, file="data/debate_metadata_1840.RData")
debate_metadata_1850 <- hansard %>%
filter(decade == 1850) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1850, file="data/debate_metadata_1850.RData")
debate_metadata_1860 <- hansard %>%
filter(decade == 1860) %>%
select(sentence_id, speechdate, debate, speaker, disambig_speaker)
debate_metadata_1860 <- hansard %>%
filter(decade == 1860) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1860, file="data/debate_metadata_1860.RData")
debate_metadata_1870 <- hansard %>%
filter(decade == 1870) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1870, file="data/debate_metadata_1870.RData")
debate_metadata_1880 <- hansard %>%
filter(decade == 1880) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1880, file="data/debate_metadata_1880.RData")
debate_metadata_1890 <- hansard %>%
filter(decade == 1890) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1890, file="data/debate_metadata_1890.RData")
debate_metadata_1900 <- hansard %>%
filter(decade == 1900) %>%
select(sentence_id, speechdate, debate)
save(debate_metadata_1900, file="data/debate_metadata_1900.RData")
tools::resaveRdaFiles("data/")
library(dplyr)
library(data.table)
dataverse_dir <- "~/projects/hansard-corpus/dataverse_upload/"
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv") %>%
mutate(year = year(hansard$speechdate)) %>%
mutate(decade = year - year %% 10)
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv") %>%
mutate(year = year(hansard$speechdate)) %>%
mutate(decade = year - year %% 10)
library(dplyr)
library(data.table)
dataverse_dir <- "~/projects/hansard-corpus/dataverse_upload/"
hansard <- fread("/home/stephbuon/data/hansard_justnine_w_year.csv") %>%
mutate(year = year(hansard$speechdate)) %>%
mutate(decade = year - year %% 10)
